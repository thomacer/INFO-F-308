\documentclass[letterpaper]{article}
\usepackage{natbib,alifexi}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[tocage]{appendix}
\usepackage[frenchb]{babel}
\usepackage[T1]{fontenc}
\usepackage{placeins, latexsym, amssymb}
\usepackage[hidelinks]{hyperref}
\usepackage{url}

\title{Manipulations de grands entiers: arithmétique en multiprécision}
\author{Thomas Perale\\
    \mbox{}\\\\
    Université Libre de Bruxelles, Département d'Informatique\\
    tperale@ulb.ac.be\\
}

\setlength{\parskip}{0.5em}

\begin{document}

\maketitle

\section{Introduction}

L'arithmétique en multiprécision offre des méthodes pour faire des opérations
sur des nombres entiers d'une taille arbitraire. Pour résoudre des problèmes
qui ont besoin d'utiliser des techniques d'arithmétique en multiprécision des
bibliothèques existent, par exemple \emph{GMP} et \emph{GNU MPFR} qui sont les plus
répandues. Elles implantent toutes les deux plusieurs algorithmes plus ou moins
efficaces selon les cas et moins naturels que ceux utilisés pour la simple
précision.
Je m'attarderai ici sur les différents algorithmes utilisés pour faire de
la multiplication en multiprécision sur des entiers et me baserai ensuite sur
la bibliothèque \emph{GMP} pour expliquer concrètement les méthodes employées.

\section{Qu'est-ce que c'est l'artithmétique en multiprécision}

L'arthmétique en multiprécision regroupe toutes les techniques utilisées dans des
programmes pour résoudre des opérations sur des nombres de taille
arbitraire (\cite{wikimultiprecision}).
Celle-ci s'oppose à l'arithmétique en simple précision qui ne s'occupe que des
nombres entre 8 et 64 bits, selon l'architecture de l'ordinateur où est executé
le programme, et dont les opérations sont des instructions physiques du
processeur (\cite{wikimultiprecision}).

\section{Les opérations simple précision}

Les opérations en simple précision sont naturellement implantées comme des
instructions du processeur ce qui offre un avantage de rapidité. Ces opérations
sont parfois émulées comme dans des languages tel que \emph{Java}.\\

Les opérations sont les suivantes (\cite{wikialu}):

\begin{itemize}
  \item L'addition;
  \item L'addition avec report;
  \item La soustraction;
  \item La soustraction avec report;
  \item Incrémentaion;
  \item Décrémentation;
  \item ET logique;
  \item OU logique;
  \item OU exclusif logique;
  \item Complément à un;
  \item Décalage à gauche ou à droite;
  \item Rotation;
  \item Rotation avec report;
  \item etc \dots
\end{itemize}

Ces opérations sont importantes parce qu'elles sont à la base des algorithmes
utilisés pour les opérations en multiprécision.

\subsection{Représentation}

La représentation des nombres en simple précision est totalement dépendante de
l'architecture de l'ordinateur sur lequel ces opérations sont executées.
Généralement les nombres entiers sont représentés dans les architectures
actuelles sous forme d'un nombre binaire de 64 bits en complément à deux.

\section{L'arithmétique multiprécision}

La forme des nombres en multiprécision n'étant pas leur forme
\emph{naturelle}, les opérations n'ont pas de solution physique offerte
par le processeur mais doivent se baser sur les opérations qu'il offre pour créer
des nouveaux algorithmes. Comme les représentations n'ont plus la contrainte
du format des nombres de l'architecture du processeur, la représentation peut
varier selon les opérations et leurs opérandes.

\subsection{Représentation vectorielle}

Lorsque les nombres sont plus grands que la limite imposée par l'architecture,
afin de faire de l'arithmétique en multiprécision, les nombres peuvent être
représentés dans une forme vectorielle. C'est-à-dire que chaque nombre est
représenté par un vecteur d'entiers de taille adaptée à la représentation
en arithmétique simple sous-jacente.

Dans notre cas on leur donnera cette notation:

  $$u = (u_{n-1} \dots u_1 u_0)$$

Qui illustre la division du nombre en multiple éléments du vecteur.

\subsection{Représentation modulaire}

La représentation modulaire est utilisée parce qu'elle permet de ne pas
travailler sur les nombres eux-mêmes mais sur les restes de leur division
ainsi que sur les différents modulos ou bases (\cite{wikiamodulaire}).\\

Si on utilise des nombres $(m_{n - 1}, \dots m_1, m_0)$ premiers entre eux,
on peut facilement calculer

  $$u_{n - 1} = u \mod m_{n - 1}$$
  $$\dots$$
  $$u_1 = u \mod m_1$$
  $$u_0 = u \mod m_0$$

On sait retrouver $u \bmod \prod m_i$ à partir de $u_{n - 1}, \dots, u_1, u_0$,
et donc retrouver $u$ si $0 ≤ u < \prod m_i$,  ce qui est une conséquence du
\emph{théorème du reste chinois}. Par conséquent $u$ peut être représenté par
un vecteur $(u_{n - 1}, \dots, u_{1}, u_{0})$\\

L'arithmétique modulaire est particulièrement utile dans le domaine de la
cryptographie où les multiplications, additions, exponentiations et réductions
modulos sont très fréquentes. Les représentations modulaires réalisent ces
opérations directement sur chaque élément, et en parallèle.

\section{Algorithme des opérations multiprécisions}

\subsection{Représentation vectorielle}

\subsubsection{Addition}

L'algorithme pour réaliser une addition sous forme vectorielle est simple.
Il se base sur l'addition en simple précision tout en ayant l'avantage de
pouvoir faire des additions sur des nombres de taille arbitraire. \\

L'algorithme d'addition des nombres en représentation vectorielle est une
application de la méthode \emph{calcul écrit} mais appliqué sur une base
différente, dépendante de l'architecture. Pour effectuer l'addition de $u =
(u_{n - 1}, \dots, u_1, u_0)$ par $v = (v_{n - 1}, \dots, v_1, v_0)$ il faut
additionner un par un chaque élément du vecteur $u$ par son élément
correspondant dans le vecteur $v$ en s'assurant que les reports éventuels
soient ajoutés à l'élément suivant du vecteur.\\

Soit $r = (r_{n - 1}, \dots, r_{1}, r_{0})$ le vecteur des reports de
l'addition où chaque élément équivaut à $1$ ou $0$ selon que l'addition aie un
report comme résultat ou non. Le résultat de l'addition est le suivant.

$$w = (r_{n - 1}, u_{n - 1} + v_{n - 1} + r_{n - 2}, \dots, u_1 + v_1 + r_0, u_0 + v_0)$$

La complexité de cet algorithme est linéaire, elle  dépend du nombre d'élément
dans le vecteur.
La réponse sera un vecteur de même taille que le plus grand des opérandes
utilisés dans l'addition ou de taille $n + 1$ si l'addition des éléments $n - 1$
du vecteur a un report.\\

J'ai parlé ici de l'addition, mais le principe est le même pour la soustraction
si les nombres sont représentés sous la forme d'un complément à deux, car il
permet d'effectuer les opérations sur des nombres négatifs de la même
manière (\cite{wikicomplementtwo}).

\subsubsection{Multiplication}

C'est la multiplication qui est au coeur de l'arithmétique en multiprécision,
car plus une multiplication implique des grands nombres, plus il existe des
manières d'optimiser l'opération.\\

On pourrait, de la même manière que pour l'addition, utiliser la méthode
\emph{''calcul écrit''} ce qui pour la multiplication nous donne un algorithme de
complexité quadratique selon la taille des opérandes.
En effet, pour effectuer la multiplication d'un nombre de taille $m$ par un nombre
de taille $n$ il faut $cnm$ opérations (avec $c$ un nombre constant
d'opérations).
Cette approche est tout à fait correcte quand on doit manipuler des petits
nombres mais demande trop de ressources pour manipuler de grands nombres alors
qu'il existe des alternatives plus efficaces.

\subsubsection{L'algorithme de Karatsuba ou Toom-2}

Cet algorithme permet de résoudre la multiplication d'un nombre
$u = (u_{n-1} \dots u_1 u_0)$ par un nombre $v = (v_{n-1} \dots v_1 v_0)$
avec une complexité de $\mathcal{O}(n^{\log{3}/\log{2}})$.\\

Afin d'y arriver, les nombres $u$ et $v$ sont divisés en deux parties de taille
égale:

  $$u = u_1 t + u_0$$
  $$v = v_1 t + v_0$$

Avec $t$ le décalage de $u_1$ et $v_1$ pour diviser $u$ et $v$ en deux parties.
On choisit évidemment $t = 2^\alpha$ où $\alpha$ est multiple de la taille en
simple précision pour que découpe et recomposition soient des opérations non
coûtantes.\\

Diviser les opérandes en deux parties permet de résoudre la multiplication
de la façon suivante

  $$uv = (t^{2} + t) u_1 v_1 + t (u_1 - u_0) (v_0 - v_1) + (t + 1) u_0 v_0$$

Cette opération réduit un problème de complexité quadratique à 3 multiplications
ainsi que des \emph{shifts} et des additions.
L'algorithme a une complexité $\mathcal{O}(N^{\log{3}/\log{2}})$ ce qui
correspond à $3$ multiplications sur des nombres $\frac{1}{2}$ fois plus petits
que les originaux (\cite{gmplibkaratsuba}).
L'algorithme est tout particulièrement efficace lorsque les opérandes sont déjà
en représentation vectorielle avec un vecteur de taille 2, l'opération de
division devient alors une étape inutile de l'algorithme. Sinon, l'algorithme
doit être appliqué récursivement sur ces nombres de taille demi jusqu'à arriver
à une taille pouvant être directement traitée en simple précision.

\subsubsection{L'algorithme Toom-3}

Toom-3 est un autre algorithme utilisé pour la multiplication de deux
entiers. Pour se faire, chaque opérande est divisé en 3 (là où Karatsuba
divisait en 2) parties de taille égale. Ces parties sont traitées comme les
coefficients de deux polynomes (\cite{gmplib2014}).

    $$X(t) = x_2 t^2 + x_1 t + x_0$$
    $$Y(t) = y_2 t^2 + y_1 t + y_0$$

Avec $t$ qui est comme pour \emph{Karatsuba} le décalage à appliquer à chaque
partie de $X$ et $Y$ pour le diviser en trois parties.
Le résultat de la multiplication aura donc la forme suivante

    $$W(t) = X(t) Y(t) =  w_4 t^4 + w_3 t^3 + w_2 t^2 + w_1 t + w_0$$

On sait qu'un polynome de degré $d$ peut être défini par $d + 1$ points. Cette
propriété est utilisée par l'algorithme pour réduire le nombre d'opérations,
en évaluant le polynome en $0, 1, -1, -2$ ce qui enlève des multiplications
à l'opération $X(t) Y(t)$ ainsi qu'en $\infty$ (ce qui correspond à ne garder
que le coefficient directeur) (\cite{wikitoom3})\\

Le polynome $X(t)$ évalué vaut donc

    $$X(0) = x_{0} + x_{1} (0) + x_2 {(0)}^{2} = x_{0}$$
    $$X(1) = x_0 + x_1(1) + x_2{(1)}^2 = x_0 + x_1 + x_2$$
    $$X(-1) = x_0 + x_1(-1) + x_2{(-1)}^2 = x_0 - x_1 + x_2$$
    $$X(2) = x_0 + x_1(2) + x_2{(2)}^2 = x_0 - 2 * x_1 + 4 * x_2$$
    $$X(\infty) = x_2$$

Et le polynome $Y(t)$ qui se construit de façon similaire. Le polynome $W(t)$
équivaut à

    $$W(0) = X(0)Y(0) = w_0$$
    $$W(1) = X(1)Y(1) = w_4 + w_3 + w_2 + w_1 + w_0$$
    $$W(-1) =X(-1)Y(-1) = w_4 - w_3 + w_2 - w_1 + w_0$$
    $$W(2) = X(2)Y(2) = 16 w_4 + 8 w_3 + 4 w_2 + 2 w_1 + w_0$$
    $$W(\infty) = X(\infty)Y(\infty)$$

Les calculs précédents peuvent être représentées sous forme matricielle

$$
\begin{pmatrix}
  W (0) \\
  W (1) \\
  W (-1) \\
  W (2) \\
  W (\infty) \\
\end{pmatrix}
 =
\begin{pmatrix}
  1 & 0 & 0 & 0 & 0 \\
  1 & 1 & 1 & 1 & 1 \\
  1 &-1 & 1 &-1 & 1 \\
  1 & 2 & 4 & 8 &16 \\
  0 & 0 & 0 & 0 & 1 \\
\end{pmatrix}
\begin{pmatrix}
  w_4 \\
  w_3 \\
  w_2 \\
  w_1 \\
  w_0 \\
\end{pmatrix}
$$

L'intérêt pour nous est de retrouver $(w_0, w_1, w_2, w_3, w_4)$ qui va nous
permettre de calculer $W$ la solution de $X.Y$ car on peut facilement calculer
$(W(0), W(1), W(-1), W(2), W(\infty))$, en effet

$${\displaystyle
\begin{pmatrix}
  W(0) \\
  W(1) \\
  W(-1) \\
  W(2) \\
  W(\infty) \\
\end{pmatrix}
=
\begin{pmatrix}
  x_2y_2 \\
  (4x_2 + 2x_1 + x_0) (4y_2+ 2y_1 + y_0)\\
  (x_2 - x_1 + x_0) (y_2 - y_1 + y_0)\\
  (x_2 + x_1 + x_0) (y_2 + y_1 + y_0)\\
  x_0y_0\\
\end{pmatrix}
}$$

Dés lors, la solution est

$$
\begin{pmatrix}
  w_4 \\
  w_3 \\
  w_2 \\
  w_1 \\
  w_0 \\
 \end{pmatrix}
=
\begin{pmatrix}
  1 & 0 & 0 & 0 & 0 \\
  1 & 1 & 1 & 1 & 1 \\
  1 &-1 & 1 &-1 & 1 \\
  1 &-2 & 4 &-8 &16 \\
  0 & 0 & 0 & 0 & 1 \\
\end{pmatrix}^{-1}
\begin{pmatrix}
  W(0) \\
  W(1) \\
  W(-1) \\
  W(2) \\
  W(\infty) \\
\end{pmatrix}
$$

Une fois qu'on a trouvé $(w_0, w_1, w_2, w_3, w_4)$ on peut calculer la
solution $W$ de la multiplication en faisant

  $$W(t) = w_4 t^4 + w_3 t^3 + w_2 t^2 + w_1 t + w_0$$

En appliquant le décalage $t$ calculé initialement.

\subsubsection{Les autres versions de Toom}

Comme on l'a vu, les algorithmes précédents de Toom-2 et de Toom-3 utilisent
tous les deux le même processus. Ils divisent les opérandes en $n$ parties
de taille égale pour former un polynome qui est évalué en $n - 1$
points.\\
Le concept est extensible à l'infini, en ajoutant des coefficients aux
polynomes créés à partir des opérandes, on diminue la complexité de la
multiplication au fur et à mesure que le degré du polynome augmente.\\
Le problème est que plus on augmente le nombre de coefficients des polynomes
plus on doit effectuer des calculs matriciels compliqués. À cause de ça, pour
qu'on observe un gain de performance, on doit utiliser des opérandes de taille
de plus en plus conséquente pour chaque coefficient ajouté.

\subsection{Représentation modulaire}

\subsubsection{Addition}

L'addition en représentation modulaire est calculée de la façon suivante

\begin{equation}
  \begin{split}
    (u_1, \dots, u_r) + (v_1, \dots, v_r) \\
     \Rightarrow ((u_1 + v_1) \bmod m_1, \dots, (u_r + v_r) \bmod m_r)
  \end{split}
\end{equation}
\begin{equation}
  \begin{split}
    (u_1, \dots, u_r) - (v_1, \dots, v_r) \\
      \Rightarrow ((u_1 - v_1) \bmod m_1, \dots, (u_r - v_r) \bmod m_r)
  \end{split}
\end{equation}

\subsubsection{Multiplications}

De la même manière pour effectuer une multiplication entre deux nombres en
représentation modulaire

\begin{equation}
  \begin{split}
    X = U.V \pmod M
  \end{split}
\end{equation}

On peut la calculer de la sorte

\begin{equation}
  \begin{split}
    (u_1, \dots, u_r)  (v_1, \dots, v_r) \mod M \\
      \Rightarrow ((u_1 v_1) \mod m_1, \dots, (u_r v_r) \mod m_r)
  \end{split}
\end{equation}

\subsubsection{La réduction de Montgomery}

La réduction de Montgomery est un algorithme qui permet d'effectuer une
multiplication modulaire de manière efficace (\cite{menezes1996crypto}).\\

Soit un entier $n$ strictement positif et $R$ et $T$ des entiers tels que $R >
n$ et $pgcd(R, n) = 1$ et $0 < T < Rn$, la réduction de Montgomery est la
méthode utilisée pour résoudre $T R' \mod n$. Selon le choix de $R$ la
réduction peut être calculée de manière efficace (\cite{menezes1996crypto}).\\

La forme \emph{Montgomery} d'une multiplication de $u$ par $v$ est la
suivante (\cite{wikimontgomery})

$$(uR \bmod N)(vR \bmod N) R' ≡ (uR)(vR) R' ≡ (u.v) R \pmod N$$

Avec un entier $R'$ qui résout $RR' = 1 \pmod N$.\\

La réduction de Montgomery est totalement adaptéé pour résoudre des opérations
en multiprécision car elle permet de réduire la taille des nombres sur lesquels
on fait des opérations. Typiquement, une implantation de l'algorithme de
Montgomery s'assurerra que $R$ soit égal à $R = b^{x}$ ($b$ étant la base
utilisée, c'est-à-dire 2 dans le cadre d'un ordinateur et $x$ un nombre qui
résout $pgcd(R, n) = 1$) pour que les opérations intermédiaires puissent être
faites grâce à des \emph{shifts} (\cite{djguan2003montgomery}).

% $$RR' - NN' = 1$$

% u = 7
% v = 15
% N = 17
% R = 100
% (7.100 mod 17 = 3) and (15.100 mod 17 = 4) et 3.4 = 12
% RR' - NN' =  8⋅100 − 47⋅17 = 1, -> R' = 8 et N' = 47
% (uR.vR).R' mod 17 = 12*8 mod 17 = 96 mod 17 = 11

\section{La bibliothèque GMP}

\subsection{Introduction}

La bibliothèque \emph{GMP} (GNU Multiple Precision Arithmetic Library) est une
bibliothèque libre permettant d'effectuer de l'arithmétique en multiprécision sur
des entiers, comme sur des nombres rationnels en se focalisant sur les
performances. La bibliothèque choisit les algorithmes selon la taille des
opérandes pour offrir les meilleures performances au cas par cas, mais optimise
aussi ses algorithmes selon l'architecture sur laquelle ils sont executés.\\

Cette bibliothèque est souvent utilisée pour des applications liées à la
cryptographie, l'analyse numérique ou les mathématiques expérimentales
(\cite{wikigmp}).

\subsection{Les algorithmes de multiplication}

Les sections précédentes nous ont montré qu'on pouvait appliquer récursivement
ces algorithmes pour diminuer la complexité des algorithmes de multiplication.
Il est légitime de se demander pourquoi ne pas utiliser l'algorithme
qui a la complexité la plus petite et quel algorithme utiliser dans
quelle situation.\\

La réponse à la première question est que ces algorithmes deviennent
plus performants à partir du moment où les nombres multipliés sont
suffisamment grands. Le nombre d'opérations qui s'exécutent en temps constant
étant de plus en plus élevé en fonction de la progression des versions de $Toom$,
ceux-ci sont plus lents pour des petits nombres que des algorithmes de
multiplication basique (de complexité quadratique)\\

Pour ce qui est de choisir un algorithme adéquat à la multiplication,
la bibliothèque GMP a choisi d'implanter 7 algorithmes de multiplication
qui sont utilisés au fûr et à mesure que la taille des opérandes
augmente (\cite{gmplibmultiplication}).

\begin{itemize}
  \item La multiplication basique;
  \item Karatsuba;
  \item Toom-3;
  \item Toom-4;
  \item Toom-6.5;
  \item Toom-8.5;
  \item FFT.
\end{itemize}

Les algorithmes de \emph{multiplication basique}, de \emph{Karatsuba} et de
\emph{Toom-3} ont déjà été abordés et c'est inutile d'en reparler car leur
implantation est la même à l'exception qu'ils sont spécialement optimisés pour
chaque processeur avec des instructions en assembleur particulières.\\

Par contre \emph{Toom-4}, \emph{Toom-6.5}, \emph{Toom-8.5} n'ont pas été
décrits car le fonctionnement est similaire. En effet, \emph{Toom-4} ne
fait que diviser le nombre en 4 coefficients là où \emph{Toom-3} le divisait en
3 coefficients (\cite{gmplibtoom4}) et évalue $X(t)$ et $Y(t)$ en 7 points.
Pour ce qui est des algorithmes \emph{Toom-x.5} ça signifie qu'on évalue $X(t)$
et $Y(t)$ en $2n$ points mais le foncitonnement est identique
(\cite{gmplibtoomhalf}).\\

La bibliothèque implante directement des \emph{seuils}, pour lesquels
on passe d'une opération à l'autre, qui sont définis par la taille en bit des
deux opérandes. Ces seuils varient selon beaucoup de paramètres dont
l'architecture. Les seuils par défaut définis par \emph{GMP} pour passer d'un
algorithme à un autre sont

\begin{itemize}
  \item $30$ pour passer à Karatsuba
  \item $100$ pour passer à Toom-3
  \item $300$ pour passer à Toom-4
  \item $350$ pour passer à Toom-6.5
  \item $450$ pour passer à Toom-8.5
\end{itemize}

\subsection{La représentation modulaire dans GMP}

La bibliothèque \emph{GMP} utilise moins la représentation modulaire pour résoudre les
opérations en multiprécision, c'est sûrement dû au fait que \emph{GMP} n'est pas
une bibliothèque faite spécifiquement pour résoudre des opérations liées à la
\emph{cryptographie}. Néanmoins, elle utilise la \emph{réduction de Montgommery}
pour résoudre des \emph{exponentiations modulaires} (\cite{gmplibmodularpowering}) que
je n'ai pas abordé dans ce papier mais qui résolvent des problèmes de la forme
suivante

$$c \equiv b^{e} \pmod {m}$$

Avec $b$ la base, $e$ l'exposant et $m$ un entier.

\subsection{FFT}

La transformation de Fourier rapide est plus particulier que les autres
algorithmes de \emph{Toom} présenté (même si il garde la même structure),
c'est pourquoi je vais rapidement le présenté sans entrer dans les détails.
\emph{FFT} est le dernier algorithme, utilisé dans la librairie \emph{GMP}
(\cite{gmplibfft}).\\

L'algorithme permait de résoudre une multiplication

$$xy \pmod 2^{M} + 1$$

Où $M$ est un nombre plus grand que la somme de la taille de $x$ et $y$ en
\emph{bits}. L'algorithme reprend les étapes de \emph{Toom-k}, mais là où
\emph{Toom-k} créait des polynomes de degré $k$ opérandes, \emph{FFT-k} crée
un polynome de degré $2^{k}$. Toutes les opérations qui sont invoqués au cours
de l'algorithme (pour l'étapes d'évaluation du polynome par exemple) se font
toujours \emph{modulo} de $2^{M'} + 1$ où $M' = 2\frac{M}{2^{k}}+k+3$ arrondi à
un multiple de $2^k$ (\cite{gmplibfft}).\\

L'évaluation se fait sur les points $g^i$ pour $i = 0$ à $2^{k}+1$ et où
$g = 2^{\frac{2M'}{2^k}}$ (\cite{gmplibfft}).

\section{Conclusion}

Les algorithmes de multiprécision sont aujourd'hui indispensables même si
beaucoup d'applications de la vie quotidienne ne sont pas contraintes par les
architectures actuelles. C'est un tout autre discours pour la sécurité
informatique, les recherches en mathématique, en physique ou encore dans
d'autres domaines qui demandent de manipuler des grands nombres. La sécurité
informatique par exemple est de plus en plus utilisée et importante pour
les utilisateurs d'ordinateur, il suffit de visiter un site internet pour
qu'on exécute sur nos ordinateurs des algorithmes qui se basent sur les
méthodes et les représentations qu'on a vu plus haut, et c'est là que c'est
important de savoir que des bibliothèques comme \emph{GMP} portent une attention
particulière à l'optimisation de ces algorithmes pour chacune des architectures
sur lesquelles elles pourraient être executées.\\

Il est important de comprendre, suite à la lecture de ce papier, qu'il n'existe
jamais de solution universelle lorsqu'il s'agit de résoudre des opérations en
multiprécision. En effet, chaque opération doit être prise au cas par
cas. On a pu étudier que des facteurs comme la taille des opérandes, le type de
représentation ou encore l'agencement des opérations avaient leur importance
pour optimiser les opérations et améliorer les performances au maximum.\\

De plus, j'ai choisi de ne pas aborder des algorithmes qui ont leur place
ici pour ne pas parler trop en détail du sujet. C'est le cas de l'algorithme
\emph{FFT} (Fast Fourier Transform), qui est par ailleurs utilisé dans
la bibliothèque \emph{GMP}, ou l'algorithme de \emph{Schönhage et Strassen} qui
sont asymptotiquement plus efficaces que les algorithmes de \emph{Toom} mais
qui dépassent le cadre d'une introduction à l'arithmétique en multiprécision.\\

J'ai aussi choisi de ne pas comparer \emph{GMP} avec d'autres bibliothèques
faisant de l'arithmétique multiprécision comme par exemple \emph{GNU MPFR} ou
\emph{OpenSSL}. Il aurait été intérressant de faire une évaluation des
performances selon les opérations de chacune d'elle pour savoir quelles sont les
applications où une bibliothèque est plus intéressante qu'une autre.\\

Si le lecteur veut s'informer plus sur les algorithmes abordés ici, il est
particulièrement intérressant de lire les implantations des algorithmes par
\emph{GMP}, on y apprend plus sur les optimisations de performance
operées par les créateurs de la bibliothèque.

\footnotesize

\bibliographystyle{apalike}
\bibliography{bibliography}

\end{document}
