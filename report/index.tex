\documentclass[letterpaper]{article}
\usepackage{natbib,alifexi}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[tocage]{appendix}
\usepackage[frenchb]{babel}
\usepackage[T1]{fontenc}
\usepackage{placeins, latexsym, amssymb}
\usepackage[hidelinks]{hyperref}
\usepackage{url}

% \documentclass[letterpaper]{article}
% \usepackage[utf8]{inputenc}
% \usepackage{natbib,alifexi}
% \usepackage{amsmath}

\title{Manipulations de grands entiers: arithmétique multiprécision}
\author{Thomas Perale\\
    \mbox{}\\\\
    Université Libre de Bruxelles, Département d'Informatique\\
    tperale@ulb.ac.be\\
}

\setlength{\parskip}{0.5em}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

L'arithmétique multiprécision offre des méthodes pour faire des opérations sur
des nombres d'une taille arbitraire. Pour résoudre des problèmes qui ont
besoins d'utiliser des techniques d'arithmétique multiprécision des librairies
existent. Par exemple \emph{GMP} et \emph{GNU MPFR} qui sont les plus
répendues elles implémentent toutes les deux plusieurs algorithmes pour faire
des opérations qui sont plus ou moins efficace selon le cas et moins naturelles
que ceux utilisé pour la simple précision.
Je m'attarderai ici sur les différents algorithmes utilisées pour faire de
de la multiplication multiprécision sur des entiers et me baserai ensuite sur
la librairie \emph{GMP} pour expliquer concrètement les méthodes employés pour
faire des opérations multiprécisions.

\section{Qu'est-ce que c'est l'artithmétique multiprécision}

L'arthmétique multiprécision regroupe toutes les techniques utilisé dans des
programmes pour résoudre des opérations sur des nombres de taille
arbitraire\cite{wikimultiprecision}.
Celle-ci s'oppose à l'arithmétique simple précision qui ne s'occupe que des
nombres entre 8 et 64 bits selon l'architecture de l'ordinateur où est executé
le programme, et dont les opérations sont des instructions du
processeurs\cite{wikimultiprecision}.

\section{Les opérations simple précision}

Les opérations simple précision sont régulièrement implémenté comme des
instructions processeurs ou sont émulés ce qui offre un avantage de rapidité.
Les opérations sont les suivantes\cite{wikialu}:

\begin{itemize}
  \item L'addition.
  \item L'addition avec report. Si l'addition dépasse la limite de
    l'architecture, c'est indiqué dans un report.
  \item La soustraction.
  \item La soustraction avec report.
  \item Incrementaion.
  \item Decrémentation.
  \item ET logique.
  \item OU logique.
  \item OU exclusif logique.
  \item Complément à un.
  \item Décalage à gauche ou à droite.
  \item Rotation
  \item Rotation avec report.
\end{itemize}

Ces opérations sont importante parce qu'elles sont à la base des algorithmes
utilisé pour les opérations multiprécisions.

\subsection{Représentation}

La représentation des nombres en simple précision est totalement dépendante de
l'architecture de l'ordinateur sur lesquels ces opérations sont executés.
Généralement les nombres entiers sont représenté dans les architectures actuels
sous forme d'un nombre binaire de 64 bits en complément à deux.

\section{L'arithmétique multiprécision}

L'arithmétique multiprécision offre des algorithmes pour les opérations moins
évidents que ceux en simple précision mais permets de résoudre des opérations
sur des nombres de taille arbitraire. Les représentations et les algorithmes et
les représentations ne sont plus ici contraint par l'architecture du processeur
ce qui permet de varier la représentation selon l'algorithme utilisé pour
l'opération.

\subsection{Représentation vectorielle}

Si les nombres sont plus grand que la limite imposé par l'architecture, afin de
faire de l'arithmétique multiprécision, les nombres peuvent être représenter
dans une forme vectorielle. C'est à dire que le nombre est représenter dans un
vecteur d'entier lorsqu'il y a un report celui-ci est ajouté à l'élément
suivant du vecteur.

% TODO Schéma

\subsection{Représentation modulaire}

\section{État de l'art des méthodes de calcul}

\subsection{Méthode classique}

Les méthodes classiques sont décrites comme l'ensemble des méthodes primitives
d'un ordinateur\cite{knuth1997aocp}, c'est-à-dire:

\begin{itemize}
    \item L'addition ou soustraction de deux entiers de taille (n) qui donne
        un résultat de la même taille avec un report éventuel.
    \item La multiplication d'un entier de taille (n) avec un autre de taille
        (m) qui donne un résultat de taille (n + m).
    \item La division d'un entier d'une taille (m) par un autre d'une taille
        (n) qui donne un résultat d'une taille (m) avec un reste éventuel de
        taille (m).
\end{itemize}

Les algorithmes des méthodes primitives sont identiques à ceux qu'on effectue
pour résoudre un calcul à l'aide de la méthode \emph{calcul écrit} sur papier
\cite{knuth1997aocp}.

\subsubsection{Algorithme de multiplication classique}

L'algorithme classique de la multiplication pour deux entiers $u x v$ avec
$u = (u_1, u_2, \dots u_n)$ et $v = (v_1, v_2, \dots v_m)$ est basé sur la
création de produit partiel $(u_1, u_2, u_3, \dots, u_n) X v_j$ pour
$0 <= j <= m$  et ensuite additionner les bonnes bases de ces opérandes.

% Les méthodes qui vont suivre seront toutes construites sur base de ces trois
% opérations primitives.

\subsection{Arithmétique modulaire}

Il existe une autre manière de faire des opérations sur des grands nombres
en utilisant l'arithmétique modulaire qui consiste à ne pas travailler sur les
nombres eux-même mais sur les restes de leur division\cite{wikiamodulaire}.\\

Si on utilise plusieurs \emph{modulis} $(m_1, m_2, \dots m_r)$ qui sont
premiers entre eux, on peut facilement calculer

  $$u_1 = u \mod m_1$$
  $$u_2 = u \mod m_2$$
  $$\dots$$
  $$u_r = u \mod m_r$$

Et on retrouver $u$ à partir de $u_1, u_2, \dots, u_r$, ce qui
est une conséquence du \emph{théorème du reste chinois}.\\

Dès lors, on peut représenter les opérations de la manière suivante.

\begin{equation}
  \begin{split}
    (u_1, \dots, u_r) + (v_1, \dots, v_r) \\
     \Rightarrow ((u_1 + v_1) \mod m_1, \dots, (u_r + v_r) \mod m_r)
  \end{split}
\end{equation}
\begin{equation}
  \begin{split}
    (u_1, \dots, u_r) - (v_1, \dots, v_r) \\
      \Rightarrow ((u_1 - v_1) \mod m_1, \dots, (u_r - v_r) \mod m_r)
  \end{split}
\end{equation}
\begin{equation}
  \begin{split}
    (u_1, \dots, u_r) X (v_1, \dots, v_r) \\
      \Rightarrow ((u_1 X v_1) \mod m_1, \dots, (u_r X v_r) \mod m_r)
  \end{split}
\end{equation}

Les désavantages sont qu'une représentation modulaire rend difficile de
déterminer si un nombre est positif ou négatif ou de savoir si
$(u_1, \dots, u_r)$ est plus grand que $(v_1, \dots, v_r)$.

% \subsubsection{Théorème du reste chinois}

\subsubsection{Quand l'utiliser}

L'arithmétique modulaire offre réellement des avantages lorsqu'il s'agit de faire
des multiplications sur des grands nombres combinés avec des additions ou
soustractions, mais pas lorsqu'il faut diviser ou comparer.

\subsection{Diminuer la complexité des algorithmes}

Les méthodes précédentes présentaient des algorithmes qui avaient besoin de
$cnm$ opérations pour multiplier un nombre de taille $m$ par un nombre de
taille $n$ (c un nombre constant d'opération). Cette section aborde rapidement
les méthodes pour faire une multiplication en moins d'opération.
\newline
Pour multiplier deux nombres $u = (u_{2n-1} \dots u_1 u_0)$ et
$v = (v_{2n-1} \dots v_1 v_0)$ de la même taille, qu'on peut écrire sous la
forme

  $$u = 2^{n} U_1 + U_0$$
  $$v = 2^{n} V_1 + V_0$$

$U_1$ étant la moitiée la plus grande de $u$ (identique pour $V_1$ avec v) et
$U_0$ la moitiée la plus petite (identique pour $V_0$ avec $v$). On peut écrire

  $$uv = (2^{2n} + 2^n) U_1 V_1 + 2^n (U_1 - U_0) (V_0 - V_1) + (2^n + 1) U_0 V_0$$

Cette opération réduit un problème de complexité quadratique à 3 multiplications
dont des \emph{shifts} et des additions. Il s'agit de l'algorithme de
\emph{karatsuba} son implémentation sera abordée plus tard.
\newline
Même si cette méthode peut être utilisée sur les machines pour exécuter une
multiplication plus rapidement qu'avec la méthode traditionelle, son vrai
avantage est qu'on peut l'utiliser pour définir de manière récursive un
algorithme de multiplication.

% Expliquer qu'ici on divise par 2 les nombres mais on peut faire la même si on
% divise par 3 le nombre, etc ..

\section{La librairie GMP}
% Regarder comment knuth introduit TOOM.
\subsection{Introduction}

La librairie \emph{GMP} (GNU Multiple Precision Arithmetic Library) est une
librairie libre permettant d'effectuer de l'arithmétique multiprécision sur
des entiers, comme sur des nombres rationnels. Elle a la particularité de ne pas
avoir de limite de précision, si ce n'est celle de la mémoire.
\newline
Cette librairie est souvent utilisée pour des applications liées à la
cryptographie\cite{wikigmp}.

\subsection{Karatsuba ou Toom-2}

Comme expliqué dans la section précedente, \emph{l'algorithme de Karatsuba} sert
à résoudre la multiplication d'un nombre $u = (u_{2n-1} \dots u_1 u_0)$ par un
nombre $v = (v_{2n-1} \dots v_1 v_0)$. Afin d'y arriver, les nombres $u$ et $v$
sont divisés en deux parties de taille égale

  $$u = 2^{n} U_1 + U_0$$
  $$v = 2^{n} V_1 + V_0$$

Ce qui permet de résoudre la multiplication de la façon suivante

  $$uv = (2^{2n} + 2^n) U_1 V_1 + 2^n (U_1 - U_0) (V_0 - V_1) + (2^n + 1) U_0 V_0$$

Pour donner un algorithme de complexité $\mathcal{O}(N^{\log{3}/\log{2}})$ qui
correspond à $3$ multiplications sur des nombres $\frac{1}{2}$ plus petits que
les originaux\cite{gmplibkaratsuba}.

\subsection{La multiplication Toom-3}

Toom-3 est un algorithme utilisé pour la multiplication de deux très grands
entiers. Pour se faire, chaque opérande est divisé en 3 (là où karatsuba
divisait en 2) partie de taille égale afin d'être traité comme le
coefficient de deux polynomes\cite{gmplib2014}.

    $$X(t) = x_2 t^2 + x_1 t + x_0$$
    $$Y(t) = y_2 t^2 + y_1 t + y_0$$

Le résultat de la multiplication aura donc la forme suivante

    $$W(t) = X(t) Y(t) =  w_4 t^4 + w_3 t^3 + w_2 t^2 + w_1 t + w_0$$

L'approche \emph{naive} de résoudre \emph{X (t) * Y (t)} pourrait être utilisée
mais celle-ci n'apporte aucun avantage en ce qui concerne la complexité de
l'algorithme par rapport à une multiplication classique.\cite{gmplib2014}
\newline
Les polynomes de degré \emph{d} sont définis par \emph{d + 1} points. Cette
propriété est utilisée par l'algorithme pour réduire le nombre d'opération, en
évaluant le polynome en $0, 1, -1, -2, \infty$ ce qui enlève des multiplications
à l'opération $X(t) Y(t)$\cite{wikitoom3}

    $$X (0) = x_{0} + x_{1} (0) + x_2 {(0)}^{2} = x_{0}$$
    $$X(1) = x_0 + x_1(1) + x_2{(1)}^2 = x_0 + x_1 + x_2$$
    $$X(-1) = x_0 + x_1(-1) + x_2{(-1)}^2 = x_0 - x_1 + x_2$$
    $$X(2) = x_0 + x_1(2) + x_2{(2)}^2 = x_0 - 2 * x_1 + 4 * x_2$$
    $$X(\infty) = x_2$$

$$
\begin{pmatrix}
  W (0) \\
  W (1) \\
  W (-1) \\
  W (2) \\
  W (\infty) \\
\end{pmatrix}
 =
\begin{pmatrix}
  1 & 0 & 0 & 0 & 0 \\
  1 & 1 & 1 & 1 & 1 \\
  1 &-1 & 1 &-1 & 1 \\
  1 &-2 & 4 &-8 &16 \\
  0 & 0 & 0 & 0 & 1 \\
\end{pmatrix}
\begin{pmatrix}
  W_4 \\
  W_3 \\
  W_2 \\
  W_1 \\
  W_0 \\
\end{pmatrix}
$$

$$
\begin{pmatrix}
  W_4 \\
  W_3 \\
  W_2 \\
  W_1 \\
  W_0 \\
 \end{pmatrix}
=
\begin{pmatrix}
  1 & 0 & 0 & 0 & 0 \\
  1 & 1 & 1 & 1 & 1 \\
  1 &-1 & 1 &-1 & 1 \\
  1 &-2 & 4 &-8 &16 \\
  0 & 0 & 0 & 0 & 1 \\
\end{pmatrix}^{-1}
\begin{pmatrix}
  W (0) \\
  W (1) \\
  W (-1) \\
  W (2) \\
  W (\infty) \\
\end{pmatrix}
$$

$$
=
\begin{pmatrix}
  1 & 0 & 0 & 0 & 0 \\
  1 & 1 & 1 & 1 & 1 \\
  1 &-1 & 1 &-1 & 1 \\
  1 &-2 & 4 &-8 &16 \\
  0 & 0 & 0 & 0 & 1 \\
\end{pmatrix}^{-1}
\begin{pmatrix}
  x_2y_2 \\
  (4x_2 + 2x_1 + x_0) (4y_2+ 2y_1 + y_0)\\
  (x_2 - x_1 + x_0) (y_2 - y_1 + y_0)\\
  (x_2 + x_1 + x_0) (y_2 + y_1 + y_0)\\
  x_0y_0\\
\end{pmatrix}
$$

\subsection{Les autres Toom}

Les versions supérieures reprennent le même principe mais en divisant
en plus de partie de taille égale.

\subsection{Quel algorithme utiliser}

Les sections précédentes nous ont montré qu'on pouvait récursivement
infiniment diminuer la complexité des algorithmes de multiplication.
Il est légitime de se demander pourquoi ne pas utiliser l'algorithme
qui a la complexité la plus petite et quel algorithme utiliser dans
quelle situation.
\newline
La réponse à la première question est que ces algorithmes deviennent
plus rapides à partir du moment ou les nombres multipliés sont
suffisamment large. Le nombre d'opération ayant un coût constant
très élevé pour résoudre l'algorithme, ceux-ci sont plus lents
que des algorithmes de multiplication basique (en $\mathcal{O}(n^2)$)
\newline
Pour ce qui est de choisir un algorithme adéquat à la multiplication,
la librairie GMP a choisi d'implémenter 7 algorithmes de multiplication
qui sont utilisés au fûr et à mesure que la taille de l'opération
augmente\cite{gmplibmultiplication}.

\begin{itemize}
  \item La multiplication basique
  \item Karatsuba
  \item Toom-3
  \item Toom-4
  \item Toom-6.5
  \item Toom-8.5
  \item FFT
\end{itemize}

La librairie implémente directement des \emph{seuils} pour lesquels
on passe d'une opération à l'autre. Ces seuils varient selon
beaucoup de paramètres dont l'architecture. Mais, en guise d'exemple
pour multiplier $N*N$, on peut, dans certains cas, commencer à utiliser
l'algorithme de \emph{Karatsuba} plutôt que la simple multiplication
à partir de $10^{10}$\cite{gmplibkaratsuba}.


\footnotesize
\bibliographystyle{apalike}
\bibliography{bibliography}

\end{document}
uer
